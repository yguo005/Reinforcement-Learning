# -*- coding: utf-8 -*-
"""HW4_Yunyu_Guo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nKReBTRJII1QtvIviUxcjFJmjS1jCJph
"""

import os
import random
import numpy as np
from scipy.special import softmax
import re




# Haiku dataset: https://www.kaggle.com/datasets/bfbarry/haiku-dataset
# Olivia Rodrigo song lyrics dataset: https://www.kaggle.com/datasets/mehaksingal/olivia-rodrigo-lyrics-datasetl

class CharNGramLanguageModel:

  def __init__(self, n = 5):
    self.n = n
    self.count_next_letters()

  # Add next_letter as a possible next letter for the given window
  def add_next_letter_to_freq(self, window, next_letter):
    count_for_this_window = self.next_letter_frequencies.get(window, dict())
    count_for_this_window[next_letter] = count_for_this_window.get(next_letter, 0) + 1
    self.next_letter_frequencies[window] = count_for_this_window


  # Add next_letter as a possible next letter for all sub-windows of the given window
  def add_next_letter_to_all_subwindows(self, window, next_letter):
    for last_n in range(-self.n, 0):
      small_window = window[last_n:]
      self.add_next_letter_to_freq(small_window, next_letter)


  # For each file in the given directory, count how often each window of characters
  # is followed by each next character. If file_name is not None, then treats each
  # line in file_name as a file.
  def count_next_letters(self):
    self.next_letter_frequencies = {}
    file_path = os.path.join(os.getcwd(), 'stranger.txt')
    with open(file_path, 'r') as file:
      for line in file:
        window = ''
        for next_letter in line:
          self.add_next_letter_to_all_subwindows(window, next_letter)
          window = (window + next_letter)[-self.n:]
        self.add_next_letter_to_all_subwindows(window, None)

  # Get a prompt from the user and generate the remaining characters in the style
  # of the given text documents. Returns the output as a string.
  def generate(self, prompt):
    next_letter = ''
    while next_letter != None:
      prompt = prompt + next_letter
      window = prompt[-self.n:]
      next_letter = self.generate_character(window)
    return prompt


  # Given a prompt of up to n characters, randomly choose the next letter using
  # frequencies learned from the provided set of documents (or uniformly if this
  # prompt window was not in the documents)
  def generate_character(self, prompt):
    for i in range(-self.n, 0):
      window_freq = self.next_letter_frequencies.get(prompt[i:], None)
      if window_freq is not None:
        chars = list(window_freq.keys())
        freqs = [window_freq[char] for char in chars]
        return random.choices(chars, weights = self.make_weights(freqs))[0]
    return random.choice('abcdefghijklmnopqrstuvwxyz')


  def make_weights(self, freqs):
    return freqs

class ReinforcementLearning:

  def __init__(self, model: CharNGramLanguageModel, alpha = 0.7, gamma = 0.99):
    self.model = model
    self.alpha = alpha
    self.gamma = gamma

  # Ask the user for num_prompts number of prompts. Perform Q learning
  # to update weights in provided char ngram model. The criteria argument must be
  # a function which takes a string and returns a numerical score, which will be
  # used as the reward for Q learning.
  def Q_learn(self, criteria, num_prompts = 1, iterations_per_prompt = 30):
     for _ in range(num_prompts):
            for _ in range(iterations_per_prompt):
                generated_text = self.model.generate(prompt)

                # Update the model's weights using the reward
                for i in range(len(generated_text) - self.model.n):
                    window = generated_text[i:i + self.model.n]
                    next_letter = generated_text[i + self.model.n]
                    window_freq = self.model.next_letter_frequencies.get(window, {})

                    # Calculate reward for the text from start to current window plus next letter
                    current_text = generated_text[:i + self.model.n + 1]
                    reward = criteria(current_text)

                    # Update the frequency of the next letter
                    if next_letter in window_freq:
                        window_freq[next_letter] = (1 - self.alpha) * window_freq[next_letter] + self.alpha * (reward + self.gamma * max(window_freq.values()))
                    else:
                        window_freq[next_letter] = self.alpha * (reward + self.gamma * max(window_freq.values(), default=0))

                    self.model.next_letter_frequencies[window] = window_freq

                # Convert negative Q-values to positive after each iteration
                for window, freq_dict in self.model.next_letter_frequencies.items():
                    min_q = min(freq_dict.values(), default=0)
                    for letter in freq_dict:
                        freq_dict[letter] = freq_dict[letter] - min_q + 1

# Reinforcement learning

# model = CharNGramLanguageModel(file_name = 'haikus.txt')


model = CharNGramLanguageModel()

prompt = input('BEFORE: Please enter the first word(s): ').strip()
print(np.average([len(model.generate(prompt)) for i in range(10)]))
print(model.generate(prompt))
ReinforcementLearning(model).Q_learn(lambda x: -len(x))
prompt = input('AFTER: Please enter the first word(s): ').strip()
print(np.average([len(model.generate(prompt)) for i in range(10)]))
model.generate(prompt)

class ReinforcementLearning:

  def __init__(self, model: CharNGramLanguageModel, alpha = 0.7, gamma = 0.99):
    self.model = model
    self.alpha = alpha
    self.gamma = gamma

  def count_positive_words(self, text):
      positive_words = ["nice", "happy", "love"]
      text = text.lower()
      word_counts = {} #dictionary

      for word in positive_words:
          count = len(re.findall(r'\b' + word + r'\b', text)) #len: how many time the word appears #boundary to match the exact word
          word_counts[word] = count * 5  # Add 5 for each occurrence

      return word_counts

  def Q_learn(self, num_prompts = 1, iterations_per_prompt = 30):
        for _ in range(num_prompts):
            for _ in range(iterations_per_prompt):
                generated_text = self.model.generate(prompt)

                # Update the model's weights using the reward
                for i in range(len(generated_text) - self.model.n):
                    window = generated_text[i:i + self.model.n]
                    next_letter = generated_text[i + self.model.n]
                    window_freq = self.model.next_letter_frequencies.get(window, {})

                    # Calculate reward for the text from start to current window plus next letter
                    current_text = generated_text[:i + self.model.n + 1]
                    word_counts = self.count_positive_words(current_text)

                    # Update the frequency of the next letter for each positive word
                    for word, count in word_counts.items():
                        if next_letter in window_freq:
                            window_freq[next_letter] = (1 - self.alpha) * window_freq[next_letter] + self.alpha * (count + self.gamma * max(window_freq.values()))
                        else:
                            window_freq[next_letter] = self.alpha * (count + self.gamma * max(window_freq.values(), default=0))

                    self.model.next_letter_frequencies[window] = window_freq

model = CharNGramLanguageModel()

prompt = input('BEFORE: Please enter the first word(s): ').strip()
print(model.generate(prompt))

ReinforcementLearning(model).Q_learn()
prompt = input('AFTER: Please enter the first word(s): ').strip()
for _ in range(10):
  print(model.generate(prompt))

class ReinforcementLearning:

  def __init__(self, model: CharNGramLanguageModel, alpha = 0.7, gamma = 0.99):
    self.model = model
    self.alpha = alpha
    self.gamma = gamma

  # Ask the user for num_prompts number of prompts. Perform Q learning
  # to update weights in provided char ngram model. The criteria argument must be
  # a function which takes a string and returns a numerical score, which will be
  # used as the reward for Q learning.
  def Q_learn(self, criteria, num_prompts = 1, iterations_per_prompt = 30):
     for _ in range(num_prompts):
            for _ in range(iterations_per_prompt):
                generated_text = self.model.generate(prompt)

                # Update the model's weights using the reward
                for i in range(len(generated_text) - self.model.n):
                    window = generated_text[i:i + self.model.n]
                    next_letter = generated_text[i + self.model.n]
                    window_freq = self.model.next_letter_frequencies.get(window, {})

                    # Calculate reward for the text from start to current window plus next letter
                    current_text = generated_text[:i + self.model.n + 1]
                    reward = criteria(current_text)

                    # Update the frequency of the next letter
                    if next_letter in window_freq:
                        window_freq[next_letter] = (1 - self.alpha) * window_freq[next_letter] + self.alpha * (reward + self.gamma * max(window_freq.values()))
                    else:
                        window_freq[next_letter] = self.alpha * (reward + self.gamma * max(window_freq.values(), default=0))

                    self.model.next_letter_frequencies[window] = window_freq

                # Apply softmax to Q-values after each iteration
                for window, freq_dict in self.model.next_letter_frequencies.items():
                    q_values = np.array(list(freq_dict.values()))
                    softmax_probs = softmax(q_values)
                    for letter, prob in zip(freq_dict.keys(), softmax_probs):
                        freq_dict[letter] = prob

model = CharNGramLanguageModel()

prompt = input('BEFORE: Please enter the first word(s): ').strip()
print(np.average([len(model.generate(prompt)) for i in range(10)]))
print(model.generate(prompt))
ReinforcementLearning(model).Q_learn(lambda x: -len(x))
prompt = input('AFTER: Please enter the first word(s): ').strip()
print(np.average([len(model.generate(prompt)) for i in range(10)]))
model.generate(prompt)